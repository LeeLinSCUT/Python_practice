（1）机器学习算法分为：监督学习，非监督学习，强化学习，推荐系统。
（2）监督学习：包含“正确答案”的数据集，算法的目的就是得出更多的正确答案。
（3）非监督学习：聚类问题和鸡尾酒会问题（音频的分离)
（4）Regression：Predict continuous valued output，线性回归的Cost Function总是趋于Convex Fucntion（凸函数）
（5）Cost Function（代价函数):是关于假设空间的一个函数，是关于假设空间的一个评价准则。最小化代价函数除了梯度下降（迭代的方法）
  正规正方程组法。
（6）矩阵的乘法能够将多个同样的输入特征（行的形式）运用到不同的线性计算（竖的形式）中。
（7）线性回归中一个参数对应一个特征量的计算，不同的样本都是这一个位置的特征量和同一个位置的参数操作。并且受该输入的特征量影响到梯度下降。 
（8）感觉特征缩放类似于Normalization
（9）多项式回归：假设函数用的是多项式，输入的特征不是经过线性的处理了而是非线性的。 
