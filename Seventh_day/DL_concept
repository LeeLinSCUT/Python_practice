(1)Logistic回归
  Logistic回归是一种广义线性回归，模型形式是w`x+b,其中w和b是待求参数。回归通过函数L将w`x+b对应一个隐状态p，p=L（w`x+b),然后根据p与1-p
  的大小决定因变量的值。如果L是logistic函数（sigmoid)，就是logistic回归。
(2)Logistic回归损失函数
  L(y^,y）=-（ylogy^+(1-y)log(1-y^))，如果当y=1的时候，我们希望y^越接近1，如果当y=0的时候，希望y^也越接近0.
（3）梯度下降法（Gradient Descent)
  w_new = w - learning_rate * gradient
（4）激活函数
  tanh_function,sigmoid_function:缺点是当输入的激活值很大或者很小的时候，值的梯度都趋于0，这样会减慢梯度下降的速度。可以作为输出函数的
  激活函数。
  relu_function:a=max(0,z) 修正线性单元。
 （5)权重随机初始化（Random Initialization)
 （6）TrainSet/DevelopmentSet（验证集）/TestSet
 （7）偏差和方差的权衡问题（Bias and Variance）
  高偏差导致欠拟合，高方差导致过拟合。偏差是预测值和实际值的关系，方差是预测值和预测值之间的关系。方差太大即使模型离散到了小众数据。
  偏差（bias）：偏差衡量了模型的预测值与实际值之间的偏离关系。通常在深度学习中，我们每一次训练迭代出来的新模型，都会拿训练数据进行预测，
  偏差就反应在预测值与实际值匹配度上，比如通常在keras运行中看到的准确度为96%，则说明是低偏差；反之，如果准确度只有70%，则说明是高偏差。
  方差（variance）：方差描述的是训练数据在不同迭代阶段的训练模型中，预测值的变化波动情况（或称之为离散情况）。
  从数学角度看，可以理解为每个预测值与预测均值差的平方和的再求平均数。通常在深度学习训练中，初始阶段模型复杂度不高，为低方差；
  随着训练量加大，模型逐步拟合训练数据，复杂度开始变高，此时方差会逐渐变高。
  （8）L2正则化Regularization（减少过拟合，减少方差）
      作用于成本函数，在后面加上正则化公式。L2正则化，使用了向量参数W的L2范数。如果使用L1正则化的话，很多w变量会变得稀疏。可能是有利于
      压缩模型。有一个超参数叫正则化参数。
      正则化的加入可以避免权重矩阵过大，使得一些权重参数接近于0，消除或者减弱了一些隐藏单元的影响。过拟合的原因就是网络学习能力太强了以至于能够过分地
      拟合训练集，正则化的加入给了简化网络的可能性，同时又不影响网络的结构。
  （9）Dropout正则化 
      原因：直接给我们的感觉是每个单元在每次迭代的过程中，都会随机连接到输入的Feature，因此不能依赖到任何一个Feature。会有收缩权重
      的效果，实施Dropout也会让权重压缩。
  （10）其他正则化方法：数据增强，Early Stopping，
  （11）归一化输入（Normalization）
    （i)减去均值 （ii)归一化方差 如果输入的值不平衡的话，会导致不同layer的权重取值的范围差别很大。可能导致优化的函数是一个狭长的碗（
    不平衡），然后导致梯度下降的速度变慢，对开始优化的起点选择也不友好。正则化后可以让整个cost function看起来更加平衡。
  （12）梯度消失/梯度爆炸
    产生原因：网络太深使得权值的微小变化使得梯度过小或者过大。
  （13）解决梯度消失/爆炸的方法:权重初始化
    w_l=np.random.randn(shape)*np.sqrt(2/n_l-1)  Var(w)=2/n <—使用relu情况下
    使用不同的激活函数会按照不同的方法进行初始化。
  （14）梯度检验
  （15）Mini_batch gradient descent 
    加快训练速度，相当于SGD和BGD的中间情况。
  （16）指数加权平均(属于optimization algorithms优化算法）
    V_t=β*V_t-1+(1-β)*θ_t,偏差修正是因为一开始我们设置V_0为0，所以一开始的预测值和实际值相比会小很多，β一般是很接近1的值。我们通过
    偏差修正将一开始的值提高，到后面这个提高的效果会越来越差。 
    结论：这是一种整理一堆离散数据的方法，使得数据更加具有前后关联性。因为当次新的数据不再是独立的，会受到之前的数据的影响。
  （17)Momentum梯度下降法
    计算梯度的指数加权平均数，然后又该新的梯度来更新权重。是为了减弱每一次更新梯度值方向的不确定性，保留学习方向的整体正确性。
    V_dW=βV_dw+(1-β)dw 可以减缓梯度下降的变化速度。 
    结论：重新整理了梯度的数据，使得之前的梯度信息得到了利用。 
   (18）RMSprop
    w_new = w- α*（dw/sqrt(S_dw))  S_dw=βS_dw+(1-β)(dw)^2  利用指数加权平均数，对梯度进行重新整理。然后将此值用于削减
    梯度的变化中。因为当dw很大的时候，最后更新用到的梯度值就会变小。如果dw很小的话，最后更新用到的梯度就会增加。
   （19）Adam优化算法
      将RMSprop和Momentum结合在了一起，就是把（18)中的dw换成Momentum后的V_dw，分子分母同时经过指数加权平均。
    (20)学习率衰减（learning rate decay）
    加快学习算法的一个方法是随时间慢慢减少学习率。
    原因：因为一开始的时候你可以承受比较大的学习步伐，但是到后面快要收敛到最佳的时候比较大的步伐就会让你跳过最佳点很多。减少学习率可以
    让你的loss点在最佳附近徘徊的范围减少。
    (21)Normalizing activations（Batch Normalization)
      可以使神经网络对超参数的选择更加稳定。归一化上一层的输出值z[2]。但是我们也不想隐藏单元的输出都是按照平均值0，方差为1的分布。
      于是我们把 z(i)=γz_norm+β,γ和β就是要学习的参数。让每一层的输出有不同的分布。
      why：使得每一层的神经网络更加独立，让深层次的网络不那么得依赖之前的网络输出结果的分布。因为中间层的神经网络不断收取到的输入值
      是在改变的，因此保证这些改变的输入值的一些不变性有利于增加网络的鲁棒性。
    (22)Softmax回归
    (23)
    (24)
    (25)
    (26)
    (27)
  
