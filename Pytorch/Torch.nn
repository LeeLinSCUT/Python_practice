(1)CLASS torch.nn.Module(nn.Module)
  是所有神经网络模块的父类，作为新建的模型的父类。本身是一个类。
  class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__() #调用父类的构造方法即可完成注册。
     
(2)CLASS torch.nn.Linear(in_features, out_features, bias=True)
   参数解释：in_features – size of each input sample
            out_features – size of each output sample
            bias – If set to False, the layer will not learn an additive bias. Default: True
            Applies a linear transformation to the incoming data: y = xA^T + b #最后返回的是一个Tensor
   包含的attribute：
   a）weight：模型中可学习的权重，shape:（n_output,n_input)
   b) bias: 模型中可学习的偏置 shape:(out_features) 
   两者的初始化值都在(-sqrt(k),sqrt(k))之前。k=1/(n_input) 
   
   
(3)torch.nn.functional.relu(input, inplace=False) → Tensor #input的是一个Tensor
  只是调用了result = torch.relu_(input)  ReLU(x)=max(0,x)
  
（4）Class torch.nn.Parameters
  Parameter 是torch.autograd.Variable的一个字类，常被用于Module的参数。例如权重和偏置。
  Parameters和Modules一起使用的时候会有一些特殊的属性。parameters赋值给Module的属性的时候，
  它会被自动加到Module的参数列表中，即会出现在Parameter()迭代器中。将Varaible赋给Module的时候没有这样的属性。
  这可以在nn.Module的实现中详细看一下。这样做是为了保存模型的时候只保存权重偏置参数，不保存节点值。所以复写Variable加以区分。
  参数：
  parameter.data 得到tensor数据
  parameter.requires_grad 默认为True， BP过程中会求导
  Parameter一般是在Modules中作为权重和偏置，自动加入参数列表，可以进行保存恢复。和Variable具有相同的运算。
  我们可以这样简单区分，在计算图中，数据（包括输入数据和计算过程中产生的feature map等）时variable类型，该类型不会被保存到模型中。
  网络的权重是parameter类型，在计算过程中会被更新，将会被保存到模型中。

(5)CLASStorch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')
这个标准结合了nn.LogSoftmax()和nn.NLLLoss()。
在训练一个有C种类的分类问题的时候是有用的。使用的时候，可选参数weight应该是1维的tensor，定义了各个类的权重。这个在你有一个不平衡
训练集的时候特别有用。
输入应该是一个给每一个类的未归一化的数据（行），大小应该是（minibatch，C）
标准期待类的标签范围是[0,C-1]作为target，1D的向量，深度是minibatch。如果ignore_index被规定了，也可以接受calss index0
Shape:
Input (N,C) C:number of classes  N:minibatch
Target:(N) N：minibatch
Output:

(6)CLASS torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
作用：将2D或者3D的输入进行批正则化，计算是将输入减去数学期望除以方差的平方根。同时带有一个权重和
偏置，默认权重为1，偏置为0。该层默认也会对计算的平均值和方差作Momentum的操作，
